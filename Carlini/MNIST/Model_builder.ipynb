{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from art.attacks import CarliniL2Method, CarliniLInfMethod\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train_classifier(cl, opt, x, y):\n",
    "    x.to(device)\n",
    "    y.to(device)\n",
    "    opt.zero_grad()\n",
    "    pred = cl(x)\n",
    "    pred.to(device)\n",
    "    print(pred.shape, y.shape)\n",
    "\n",
    "    err = F.nll_loss(F.log_softmax(pred, dim=0), y)\n",
    "    #     L1 regularizer\n",
    "#     with torch.enable_grad():\n",
    "#         reg = 1e-05\n",
    "#         l1_loss = torch.zeros(1)\n",
    "#         for name, param in cl.named_parameters():\n",
    "#             if 'bias' not in name:  # param is a weight tensor\n",
    "#                 l1_loss += reg*torch.sum(torch.abs(param))\n",
    "#     err += l1_loss.item()\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    return err, pred\n",
    "\n",
    "def test_model(cl,test_loader): \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        cl.eval()\n",
    "        for data, target in test_loader:\n",
    "            output = cl(data.to(device))\n",
    "            pred = output.data.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "            target = np.argmax(target, axis=1)\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        acc_test = float(correct.numpy() / len(test_loader.dataset))\n",
    "        \n",
    "    return acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 10]) torch.Size([64])\n",
      "Performance in the trained model: \n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000, 1, 28, 28])\n",
      "Test accuracy:  11.12 %\n",
      "FINISHED!!!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "e_losses = [] \n",
    "\n",
    "# Load pre-trained model\n",
    "cl = Classifier().to(device)\n",
    "\n",
    "# optimizer\n",
    "decay = 0\n",
    "cl_opt = optim.Adam(cl.parameters(), lr=0.001, weight_decay=decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cl.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        target = np.argmax(target, axis=1)  # transform from one-hot to int\n",
    "        c_error,c_pred = train_classifier(cl,cl_opt, data.to(device), target.to(device))\n",
    "        e_losses.append(c_error.cpu().data.numpy())\n",
    "        break\n",
    "    break\n",
    "    acc = test_model(cl,test_dataloader)\n",
    "    print(\"Epoch \", e, \": Test accuracy: \", 100*acc, \"%\")\n",
    "\n",
    "print(\"Performance in the trained model: \")\n",
    "acc_test = test_model(cl,test_dataloader)\n",
    "print(\"Test accuracy: \", 100*acc_test, \"%\")\n",
    "print(\"FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cl.state_dict(), \n",
    "           '../saved_models/Carlini/L1/l1_regularized_1e-05_model_03.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ART classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier with the TRAINED model\n",
    "classifier = PyTorchClassifier(\n",
    "    model=cl,\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterion,\n",
    "    optimizer=cl_opt,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 98.79 %\n"
     ]
    }
   ],
   "source": [
    "# Should yield the same accuracy as the one printed above\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carlini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CarliniL2(classifier, x_test, init_const):\n",
    "    start = time.time()\n",
    "    attack = CarliniL2Method(classifier=classifier,\n",
    "                            confidence=0.0,\n",
    "                            targeted=False,\n",
    "                            learning_rate=0.01,\n",
    "                            binary_search_steps=2,\n",
    "                            initial_const=init_const,\n",
    "                            batch_size=64)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    end = time.time()\n",
    "    print(round((end-start)/60, 3), \"mins\")\n",
    "    \n",
    "    return x_test_adv\n",
    "\n",
    "\n",
    "def CarliniLInf(classifier, x_test, epsilon):\n",
    "    start = time.time()\n",
    "    attack = CarliniLInfMethod(classifier=classifier, \n",
    "                              confidence=0.0,\n",
    "                              targeted=False, \n",
    "                              learning_rate=0.01,\n",
    "                              eps=epsilon, \n",
    "                              batch_size=128)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    end = time.time()\n",
    "    print(round((end-start)/60, 3), \"mins\")\n",
    "    \n",
    "    return x_test_adv\n",
    "\n",
    "\n",
    "# Calculate distance \n",
    "def L2distance(x_test, x_test_adv):\n",
    "    dist = 0\n",
    "    for test, adv_test in zip(x_test, x_test_adv):\n",
    "        dist += np.linalg.norm(test-adv_test)\n",
    "    dist /= len(x_test)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1329f28f4ae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CARLINI LINF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_test_adv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCarliniLInf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_adv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-33ef3891cf44>\u001b[0m in \u001b[0;36mCarliniLInf\u001b[1;34m(classifier, x_test, epsilon)\u001b[0m\n\u001b[0;32m     24\u001b[0m                               \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                               batch_size=128)\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mx_test_adv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mins\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\art\\attacks\\attack.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\art\\attacks\\evasion\\carlini.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    716\u001b[0m                     \u001b[0mx_adv_batch_tanh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mclip_min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                     \u001b[0mclip_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactive\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m                 )\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\art\\attacks\\evasion\\carlini.py\u001b[0m in \u001b[0;36m_loss_gradient\u001b[1;34m(self, z_logits, target, x_adv, x_adv_tanh, clip_min, clip_max)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mi_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_logits\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mloss_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_add\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m         \u001b[0mloss_gradient\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_sub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mloss_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\art\\classifiers\\classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\art\\classifiers\\pytorch.py\u001b[0m in \u001b[0;36mclass_gradient\u001b[1;34m(self, x, label, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[0minput_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CARLINI LINF\n",
    "x_test_adv = CarliniLInf(classifier, x_test[:1000], epsilon=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(x_test_adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.939 mins\n",
      "6.319 mins\n"
     ]
    }
   ],
   "source": [
    "# CARLINI L2\n",
    "\n",
    "constants = [0.1, 10]\n",
    "# BE CAREFULL adversarial_samples = dict()\n",
    "# adversarial_dist = dict()\n",
    "for init in constants:\n",
    "    x_test_adv = CarliniL2(classifier, x_test, init_const=init)\n",
    "    adversarial_samples[init] = x_test_adv\n",
    "    adversarial_dist[init] = L2distance(x_test, x_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 98.8 %\n"
     ]
    }
   ],
   "source": [
    "# MEASURE ADVERSARIAL ACCURACY\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:1000], axis=1)) / 1000# len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x261933efe88>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_test_adv[6].squeeze()\n",
    "# image = x_test[4].squeeze()\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adversarial_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_const: 1.0 - Accuracy on adversarial test examples: 55.84%\n",
      "init_const: 0.1 - Accuracy on adversarial test examples: 97.97%\n",
      "init_const: 10 - Accuracy on adversarial test examples: 5.18%\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "res = dict()\n",
    "for init, x_test_adv in adversarial_samples.items():\n",
    "    predictions = classifier.predict(x_test_adv)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    res[init] = accuracy*100\n",
    "    print(\"init_const: {} - Accuracy on adversarial test examples: {}%\".format(init, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_const: 0.1 - Accuracy on adversarial test examples: 98.71%\n",
      "init_const: 1.0 - Accuracy on adversarial test examples: 95.02000000000001%\n",
      "init_const: 10 - Accuracy on adversarial test examples: 88.1%\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "res = dict()\n",
    "for init, x_test_adv in adversarial_test.items():\n",
    "    predictions = classifier.predict(x_test_adv)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    res[init] = accuracy*100\n",
    "    print(\"init_const: {} - Accuracy on adversarial test examples: {}%\".format(init, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
