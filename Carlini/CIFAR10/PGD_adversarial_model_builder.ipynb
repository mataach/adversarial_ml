{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from art.attacks import CarliniL2Method, CarliniLInfMethod\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from art.attacks.evasion.projected_gradient_descent import ProjectedGradientDescent\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)\n",
    "test_dataloader_single =  DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"C:/Users/Matach/OneDrive - Imperial College London/ICL/FYP/Experiments/saved_models/CIFAR10/Adversarial PGD\")\n",
    "file = \"L2_1e-04.pth\"\n",
    "pretrained_model = os.path.join(path, file)\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc1 = nn.Linear(4096, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def train_classifier(cl, opt, x, y):\n",
    "    x.to(device)\n",
    "    y.to(device)\n",
    "    opt.zero_grad()\n",
    "    pred = cl(x)\n",
    "    pred.to(device)\n",
    "    err = F.nll_loss(F.log_softmax(pred, dim=0), y)\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    return err, pred\n",
    "\n",
    "def test_model(cl,test_loader): \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        cl.eval()\n",
    "        for data, target in test_loader:\n",
    "            output = cl(data.to(device))\n",
    "            pred = output.data.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "            target = np.argmax(target, axis=1)\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        acc_test = float(correct.numpy() / len(test_loader.dataset))\n",
    "        \n",
    "    return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Model(\n",
      "  (conv_layer): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Dropout2d(p=0.05, inplace=False)\n",
      "    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Accuracy on benign test examples: 65.86999999999999 %\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "    \n",
    "# Initialize the model.\n",
    "model = Model().to(device)\n",
    "\n",
    "# Load pre-trained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "print(model.eval())\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier \n",
    "def make_classifier(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "    # Make a classifier wrapper!\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(min_, max_),\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def adversarial_training_PGD(model, device, data, epsilon, alpha):\n",
    "    dim = data.size()\n",
    "    batch = torch.Tensor()\n",
    "    fgsm = np.random.choice([0, 1], size=dim[0], p=[.5, .5])\n",
    "    for image, is_fgsm in zip(data, fgsm):\n",
    "        # VIP Reshape image for model compatibility\n",
    "        image = image.view(1, dim[1], dim[2], dim[3])\n",
    "        image, batch = image.to(device), batch.to(device)\n",
    "        if is_fgsm:\n",
    "            classifier = make_classifier(model)\n",
    "            adv_crafter = ProjectedGradientDescent(classifier, norm=np.inf, eps=epsilon, eps_step=alpha, max_iter=7)\n",
    "            perturbed_image = adv_crafter.generate(x=image.cpu().detach().numpy())\n",
    "            batch = torch.cat((batch, torch.Tensor(perturbed_image).to(device)), dim=0)\n",
    "        else:\n",
    "            batch = torch.cat((batch, image), dim=0)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06236745581885411 0.031183727909427056\n"
     ]
    }
   ],
   "source": [
    "path = Path(\"C:/Users/Matach/OneDrive - Imperial College London/ICL/FYP/Experiments/saved_models/CIFAR10/Adversarial PGD\")\n",
    "file = \"L2_1e-04.pth\"\n",
    "\n",
    "data = np.vstack((x_train, x_test))\n",
    "cifar10_std = data.std()\n",
    "eps = (4 / 255.) / cifar10_std\n",
    "alpha = (2 / 255.) / cifar10_std\n",
    "print(eps, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Test accuracy:  44.35 %\n",
      "Epoch  1 : Test accuracy:  48.089999999999996 %\n",
      "Epoch  2 : Test accuracy:  52.78 %\n",
      "Epoch  3 : Test accuracy:  56.67 %\n",
      "Epoch  4 : Test accuracy:  57.91 %\n",
      "Epoch  5 : Test accuracy:  62.71 %\n",
      "Epoch  6 : Test accuracy:  61.9 %\n",
      "Epoch  7 : Test accuracy:  63.38 %\n",
      "Epoch  8 : Test accuracy:  63.18 %\n",
      "Epoch  9 : Test accuracy:  64.28 %\n",
      "Epoch  10 : Test accuracy:  65.88000000000001 %\n",
      "Epoch  11 : Test accuracy:  65.23 %\n",
      "Epoch  12 : Test accuracy:  65.81 %\n",
      "Epoch  13 : Test accuracy:  65.25999999999999 %\n",
      "Epoch  14 : Test accuracy:  65.86999999999999 %\n",
      "Epoch  15 : Test accuracy:  65.58 %\n",
      "Epoch  16 : Test accuracy:  66.34 %\n",
      "Epoch  17 : Test accuracy:  65.68 %\n",
      "Epoch  18 : Test accuracy:  66.22 %\n",
      "Epoch  19 : Test accuracy:  65.45 %\n",
      "Performance in the trained model: \n",
      "Test accuracy:  65.45 %\n",
      "FINISHED!!!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "e_losses = [] \n",
    "\n",
    "# Load pre-trained model\n",
    "cl = Model().to(device)\n",
    "# cl = model\n",
    "\n",
    "# optimizer\n",
    "cl_opt = optim.Adam(cl.parameters(), lr=0.001, weight_decay=1e-04)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cl.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        target = np.argmax(target, axis=1)  # transform from one-hot to int\n",
    "        new_batch = adversarial_training_PGD(cl, device, data, epsilon=eps, alpha=alpha)\n",
    "        c_error,c_pred = train_classifier(cl,cl_opt, new_batch.to(device), target.to(device))\n",
    "        e_losses.append(c_error.cpu().data.numpy())\n",
    "    acc = test_model(cl,test_dataloader)\n",
    "    torch.save(cl.state_dict(), '{name}_{epoch}'.format(name=os.path.join(path, file), epoch=e)) # save file\n",
    "    print(\"Epoch \", e, \": Test accuracy: \", 100*acc, \"%\")\n",
    "\n",
    "print(\"Performance in the trained model: \")\n",
    "acc_test = test_model(cl,test_dataloader)\n",
    "print(\"Test accuracy: \", 100*acc_test, \"%\")\n",
    "print(\"FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
