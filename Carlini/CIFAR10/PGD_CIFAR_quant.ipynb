{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGD_CIFAR_quant.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "shxD2Rg3084H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4978e8dd-fef0-496d-bb4d-abb325458657"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=ae6f13c809a2f7e1a92b6a98234069619518ac0a6150a64282ab47a3041ba3e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 160.2 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntyRDthk1DGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "e862e8c0-0c76-4857-c17c-ef4a6409ea69"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\r\u001b[K     |▊                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 102kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 112kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 122kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 133kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 143kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 174kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 184kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 194kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 204kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 215kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 225kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 235kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 245kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 256kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 266kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 276kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 286kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 296kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 307kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 327kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 337kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 348kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 358kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 368kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 378kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 389kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 399kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 409kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 419kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 430kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 440kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 450kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 460kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 471kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 481kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (47.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Collecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.15.1)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgx6e0vG1nmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.quantization\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import Tensor\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from art.attacks import CarliniL2Method, CarliniLInfMethod, ProjectedGradientDescent\n",
        "from art.classifiers import PyTorchClassifier\n",
        "from art.utils import load_cifar10\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awTtp82s1x1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
        "\n",
        "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
        "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
        "\n",
        "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1000)\n",
        "test_dataloader_single = DataLoader(test_dataset, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkqMSDWv1zb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def train_classifier(cl, opt, x, y):\n",
        "    x.to(device)\n",
        "    y.to(device)\n",
        "    opt.zero_grad()\n",
        "    pred = cl(x)\n",
        "    pred.to(device)\n",
        "    err = F.nll_loss(F.log_softmax(pred, dim=0), y)\n",
        "    err.backward()\n",
        "    opt.step()\n",
        "    return err, pred\n",
        "\n",
        "def test_model(cl,test_loader): \n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        cl.eval()\n",
        "        for data, target in test_loader:\n",
        "            output = cl(data.to(device))\n",
        "            pred = output.data.max(1, keepdim=True)[1].to(\"cpu\")\n",
        "            target = np.argmax(target, axis=1)\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "        acc_test = float(correct.numpy() / len(test_loader.dataset))\n",
        "        \n",
        "    return acc_test\n",
        "\n",
        "def print_size_of_model(model):\n",
        "  torch.save(model.state_dict(), 'temp.p')\n",
        "  print('Size (KB):', os.path.getsize(\"temp.p\")/1e3)\n",
        "  os.remove('temp.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvM-Ijqr15ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_classifier(model):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "    # Make a classifier wrapper!\n",
        "    classifier = PyTorchClassifier(\n",
        "        model=model,\n",
        "        clip_values=(min_, max_),\n",
        "        loss=criterion,\n",
        "        optimizer=optimizer,\n",
        "        input_shape=(3, 32, 32),\n",
        "        nb_classes=10,\n",
        "    )\n",
        "    return classifier\n",
        "\n",
        "\n",
        "\n",
        "def adversarial_training(model, device, data, epsilon, alpha):\n",
        "    dim = data.size()\n",
        "    batch = torch.Tensor()\n",
        "    fgsm = np.random.choice([0, 1], size=dim[0], p=[.5, .5])\n",
        "    for image, is_fgsm in zip(data, fgsm):\n",
        "        # VIP Reshape image for model compatibility\n",
        "        image = image.view(1, dim[1], dim[2], dim[3])\n",
        "        image, batch = image.to(device), batch.to(device)\n",
        "        if is_fgsm:\n",
        "            classifier = make_classifier(model)\n",
        "            adv_crafter = ProjectedGradientDescent(classifier, norm=np.inf, eps=epsilon, eps_step=alpha, max_iter=7)\n",
        "            perturbed_image = adv_crafter.generate(x=image.cpu().detach().numpy())\n",
        "            batch = torch.cat((batch, torch.Tensor(perturbed_image).to(device)), dim=0)\n",
        "        else:\n",
        "            batch = torch.cat((batch, image), dim=0)\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWwPWcbp11Vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9a15f0f-9cf0-4458-e92b-d6144b09c669"
      },
      "source": [
        "%cd '/content/drive/My Drive/Colab Notebooks/models'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFBnTqn63CO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c42c900-a554-4249-956d-587ef3bc4f8c"
      },
      "source": [
        "file = 'quant.pth'\n",
        "\n",
        "data = np.vstack((x_train, x_test))\n",
        "cifar10_std = data.std()\n",
        "eps = (4 / 255.) / cifar10_std\n",
        "alpha = (2 / 255.) / cifar10_std\n",
        "print(eps, alpha)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06236745581885411 0.031183727909427056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Z5fSaM3DlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6f9e0a65-1531-41f4-f43f-ccbbb5aca328"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "qat_model = Model().to(device)\n",
        "qat_model.config = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "# prepare_qat performs the “fake quantization”, preparing the model for quantization-aware training\n",
        "torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "cl_opt = optim.Adam(qat_model.parameters(), lr=.001, weight_decay=0)\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "  qat_model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "    target = np.argmax(target, axis=1)  # transform from one-hot to int\n",
        "    new_batch = adversarial_training(qat_model, device, data, epsilon=eps, alpha=alpha)\n",
        "    error, pred = train_classifier(qat_model.to(device), cl_opt, new_batch.to(device), target.to(device))  \n",
        "  # Check accuracy after each epoch\n",
        "  quantized_model = torch.quantization.convert(qat_model.eval(), inplace=False)\n",
        "  acc = test_model(quantized_model, test_dataloader)\n",
        "  print(\"Epoch \", e+1, \": Test accuracy: \", 100*acc, \"%\")\n",
        "  torch.save(qat_model.state_dict(), '{name}_{epoch}'.format(name=file, epoch=e+1))\n",
        "\n",
        "print(\"Performance in the trained model\")\n",
        "print('Test Accuracy: ', test_model(quantized_model, test_dataloader)*100, '%')\n",
        "print(\"FINISHED!!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/quantize.py:143: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n",
            "  warnings.warn(\"None of the submodule got qconfig applied. Make sure you \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IOLzPYX5FF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}