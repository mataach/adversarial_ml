{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks import CarliniL2Method, CarliniLInfMethod\n",
    "from art.classifiers.pytorch import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_mnist()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)\n",
    "test_dataloader_single =  DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.000001, .1, .2, .3]\n",
    "pretrained_model = \"MNIST_vanilla_model_01.pth\"\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "    \n",
    "    activations_fc2 = []\n",
    "    mask_fc2 = torch.zeros(1, 512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def forwardDetect(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        self.activations_fc2.append(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def forwardMask(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))*self.mask_fc2\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the model.\n",
    "model = Classifier().to(device)\n",
    "\n",
    "# # Load pre-trained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# # Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "print(model.eval())\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "    \n",
    "    mask_fc2 = torch.ones(1, 512)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))*self.mask_fc2.to(device)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the model.\n",
    "mask_model = MaskModel().to(device)\n",
    "\n",
    "# Load pre-trained model\n",
    "mask_model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "print(mask_model.eval())\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mask_model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "mask_classifier = PyTorchClassifier(\n",
    "    model=mask_model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = mask_classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader_single:\n",
    "        output = model.forwardDetect(data.to(device))\n",
    "\n",
    "activations_fc2 = model.activations_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(activations_fc2)\n",
    "element0 = activations_fc2.pop()\n",
    "act = torch.zeros(n,element0.size(0),element0.size(1))\n",
    "act[0,:,:] = element0\n",
    "\n",
    "for e in range(n-1):\n",
    "    elementX = activations_fc2.pop()\n",
    "    act[e+1,:,:] = elementX\n",
    "\n",
    "mean_activations_fc2 = torch.mean(act,dim=[0,1])\n",
    "ma = mean_activations_fc2.numpy()\n",
    "plt.hist(ma,80)\n",
    "plt.title('Activations FC1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save different masks for different percentages\n",
    "\n",
    "masks_fc2 = dict()\n",
    "\n",
    "for percentage in [0, 3, 6, 9]:\n",
    "#     FC2\n",
    "    s_ma_fc2, idx_ma_fc2 = torch.sort(mean_activations_fc2)\n",
    "    m_fc2 = torch.ones(mean_activations_fc2.size()).to(device)\n",
    "    nn_fc2 = mean_activations_fc2.size(0)\n",
    "    ind_r_fc2 = round((percentage/10)*nn_fc2)\n",
    "    m_fc2[idx_ma_fc2[:ind_r_fc2]] = 0.0\n",
    "    n1_fc2 = m_fc2.sum()\n",
    "    model.mask_fc2 = m_fc2\n",
    "    masks_fc2[percentage/10] = model.mask_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_prune = dict()\n",
    "n = 1000\n",
    "\n",
    "\n",
    "# Run test for each epsilon and mask PG \n",
    "for (pg, mask_fc2) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "    mask_model.mask_fc2 = mask_fc2\n",
    "    \n",
    "    for e in epsilons:\n",
    "        adv_crafter = FastGradientMethod(mask_classifier, eps=e)\n",
    "        x_test_adv = adv_crafter.generate(x=x_test[:n])\n",
    "        predictions = mask_classifier.predict(x_test_adv)\n",
    "        accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n\n",
    "        accuracies.append(accuracy)\n",
    "        print(\"Epsilon: {}   Test Accuracy = {}\".format(e, accuracy))\n",
    "\n",
    "    results['accuracies'] = accuracies\n",
    "    results['epsilons'] = epsilons\n",
    "    fgsm_prune[pg] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial test examples\n",
    "def CarliniL2(classifier, x_test, init_const):\n",
    "    attack = CarliniL2Method(classifier=classifier,\n",
    "                            confidence=0.0,\n",
    "                            targeted=False,\n",
    "                            learning_rate=0.01,\n",
    "                            binary_search_steps=2,\n",
    "                            initial_const=init_const,\n",
    "                            batch_size=64)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv\n",
    "\n",
    "def CarliniLInf(classifier, x_test, epsilon):\n",
    "    attack = CarliniLInfMethod(classifier=classifier, \n",
    "                              confidence=0.0,\n",
    "                              targeted=False, \n",
    "                              learning_rate=0.01,\n",
    "                              eps=epsilon, \n",
    "                              batch_size=128)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlini_prune = dict()\n",
    "constants = [0.1, 1.0, 5]\n",
    "n = 1000\n",
    "\n",
    "# Run test for each c and mask PG \n",
    "for (pg, mask_fc2) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "    mask_model.mask_fc2 = mask_fc2\n",
    "\n",
    "    \n",
    "    for init in constants:\n",
    "        x_test_adv = CarliniL2(mask_classifier, x_test[:n], init_const=init)\n",
    "        predictions = mask_classifier.predict(x_test_adv)\n",
    "        acc = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        print('c:', init, ' Accuracy:', acc)\n",
    "\n",
    "    results['accuracies'] = accuracies\n",
    "    results['constants'] = constants\n",
    "    carlini_prune[pg] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlini_inf_prune = dict()\n",
    "epsilons = [.1, .3, .6]\n",
    "n = 1000\n",
    "\n",
    "# Run test for each c and mask PG \n",
    "for (pg, mask_fc2) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "    mask_model.mask_fc2 = mask_fc2\n",
    "\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        x_test_adv = CarliniLInf(mask_classifier, x_test[:n], epsilon=eps)\n",
    "        predictions = mask_classifier.predict(x_test_adv)\n",
    "        acc = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        print('eps:', eps, ' Accuracy:', acc)\n",
    "\n",
    "    results['accuracies'] = accuracies\n",
    "    results['epsilons'] = epsilons\n",
    "    carlini_inf_prune[pg] = results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
