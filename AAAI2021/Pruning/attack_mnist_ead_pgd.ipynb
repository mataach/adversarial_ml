{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art.attacks.evasion import ElasticNet\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch as PGDAttack\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "from _utils import test\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_mnist()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=6)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)\n",
    "test_dataloader_single =  DataLoader(test_dataset, batch_size=1, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"MNIST_vanilla_model_01.pth\"\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "    \n",
    "    activations_fc2 = []\n",
    "    mask_fc2 = torch.zeros(1, 200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def forwardDetect(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        self.activations_fc2.append(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def forwardMask(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))*self.mask_fc2\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the model.\n",
    "model = Classifier().to(device)\n",
    "\n",
    "# # Load pre-trained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# # Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "print(model.eval())\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 512)\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "    \n",
    "    mask_fc2 = torch.ones(1, 200)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))*self.mask_fc2.to(device)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the model.\n",
    "mask_model = MaskModel().to(device)\n",
    "\n",
    "# Load pre-trained model\n",
    "mask_model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "print(mask_model.eval())\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mask_model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "mask_classifier = PyTorchClassifier(\n",
    "    model=mask_model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = mask_classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader_single:\n",
    "        output = model.forwardDetect(data.to(device))\n",
    "\n",
    "activations_fc2 = model.activations_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(activations_fc2)\n",
    "element0 = activations_fc2.pop()\n",
    "act = torch.zeros(n,element0.size(0),element0.size(1))\n",
    "act[0,:,:] = element0\n",
    "\n",
    "for e in range(n-1):\n",
    "    elementX = activations_fc2.pop()\n",
    "    act[e+1,:,:] = elementX\n",
    "\n",
    "mean_activations_fc2 = torch.mean(act,dim=[0,1])\n",
    "ma = mean_activations_fc2.numpy()\n",
    "plt.hist(ma,80)\n",
    "plt.title('Activations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save different masks for different percentages\n",
    "\n",
    "masks_fc2 = dict()\n",
    "\n",
    "for percentage in [0, 3, 6, 9]:\n",
    "    s_ma_fc2, idx_ma_fc2 = torch.sort(mean_activations_fc2)\n",
    "    m_fc2 = torch.ones(mean_activations_fc2.size()).to(device)\n",
    "    nn_fc2 = mean_activations_fc2.size(0)\n",
    "    ind_r_fc2 = round((percentage/10)*nn_fc2)\n",
    "    m_fc2[idx_ma_fc2[:ind_r_fc2]] = 0.0\n",
    "    n1_fc2 = m_fc2.sum()\n",
    "    model.mask_fc2 = m_fc2\n",
    "    masks_fc2[percentage/10] = model.mask_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy on pruned network\n",
    "for (pg, mask) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    mask_model.mask_fc2 = mask\n",
    "    predictions = mask_classifier.predict(x_test)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EAD_L1(classifier, x_test):\n",
    "    attack = ElasticNet(classifier=classifier,\n",
    "                        learning_rate=1e-2,\n",
    "                        binary_search_steps=5,\n",
    "                        max_iter=10,\n",
    "                        beta=1e-3,\n",
    "                        initial_const=1e-3,\n",
    "                        decision_rule=\"L1\")\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adversarial samples on pruned models and attack pruned models \n",
    "\n",
    "n = 1000\n",
    "for (pg, mask) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    mask_model.mask_fc2 = mask\n",
    "    x_test_adv_l1 = EAD_L1(mask_classifier, x_test[:n])\n",
    "    predictions = mask_classifier.predict(x_test_adv_l1)\n",
    "    acc = 100*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n)\n",
    "    \n",
    "    print(' Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(classifier, x_test, norm, eps):\n",
    "    attack = PGDAttack(estimator=classifier,\n",
    "                       norm=norm,\n",
    "                       eps=eps,\n",
    "                       eps_step=0.1,\n",
    "                       max_iter=100,\n",
    "                       verbose=False)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "n = 1000\n",
    "for (pg, mask) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    mask_model.mask_fc2 = mask\n",
    "    x_test_adv_l2 = PGD(mask_classifier, x_test[:n], norm=2, eps=2)\n",
    "    predictions = mask_classifier.predict(x_test_adv_l2)\n",
    "    acc = 100*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n)\n",
    "    \n",
    "    print(' Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linf\n",
    "n = 1000\n",
    "for (pg, mask) in masks_fc2.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    mask_model.mask_fc2 = mask\n",
    "    x_test_adv_linf = PGD(mask_classifier, x_test[:n], norm=np.inf, eps=.3)\n",
    "    predictions = mask_classifier.predict(x_test_adv_linf)\n",
    "    acc = 100*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n)\n",
    "    \n",
    "    print(' Accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
