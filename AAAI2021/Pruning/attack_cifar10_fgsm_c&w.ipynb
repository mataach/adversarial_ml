{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod, CarliniL2Method, CarliniLInfMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "from _utils import train, test\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)\n",
    "test_dataloader_single =  DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet18 import Bottleneck, BasicBlock\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "    \n",
    "    #     PRUNING\n",
    "    activations = []\n",
    "    mask = torch.zeros(100, 128, 16, 16)\n",
    "\n",
    "    \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def forwardDetect(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        self.activations.append(out.view(out.size(0), -1))\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        self.activations.append(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def forwardMask(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)*self.mask\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "# MASK NET FOR PRUNING!\n",
    "\n",
    "class MaskResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(MaskResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "    \n",
    "    #     PRUNING\n",
    "    mask = torch.ones(128, 128, 16, 16)\n",
    "\n",
    "    \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)*self.mask.to(device)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "def MaskResNet18():\n",
    "    return MaskResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'ResNet18.pth'\n",
    "\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize models.\n",
    "net = ResNet18().to(device)\n",
    "maskNet = MaskResNet18().to(device)\n",
    "\n",
    "# Load pre-trained model\n",
    "net.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "maskNet.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "\n",
    "\n",
    "# Load loss and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Make a classifier wrapper!\n",
    "classifier = PyTorchClassifier(\n",
    "    model=net,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "maskClassifier = PyTorchClassifier(\n",
    "    model=maskNet,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "# Test model\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))\n",
    "\n",
    "N = 128*30\n",
    "predictions = maskClassifier.predict(x_test[:N])\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:N], axis=1)) / N\n",
    "print(\"Accuracy on benign test examples: {} %\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        output = net.forwardDetect(data.to(device))\n",
    "        \n",
    "activations = net.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(activations)\n",
    "element0 = activations.pop()\n",
    "act = torch.zeros(n,element0.size(0),element0.size(1))\n",
    "act[0,:,:] = element0\n",
    "\n",
    "for e in range(n-1):\n",
    "    elementX = activations.pop()\n",
    "    act[e+1,:,:] = elementX\n",
    "\n",
    "mean_activations = torch.mean(act,dim=[0,1])\n",
    "ma = mean_activations.numpy()\n",
    "plt.hist(ma,80)\n",
    "plt.title('Activations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save different masks for different percentages\n",
    "\n",
    "masks = dict()\n",
    "\n",
    "for percentage in [0, 3, 6, 9]:\n",
    "    s_ma, idx_ma = torch.sort(mean_activations)\n",
    "    m = torch.ones(mean_activations.size()).to(device)\n",
    "    nn = mean_activations.size(0)\n",
    "    ind_r = round((percentage/10)*nn)\n",
    "    m[idx_ma[:ind_r]] = 0.0\n",
    "    n1 = m.sum()\n",
    "    net.mask = m\n",
    "    masks[percentage/10] = net.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [.001, .01, .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fgsm_prune = dict()\n",
    "\n",
    "\n",
    "# Run test for each epsilon and mask PG \n",
    "for (pg, mask) in masks.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "#     if masking a Conv layer it will need reshaping\n",
    "    mask_reshaped = torch.reshape(mask,(128, 16, 16)) \n",
    "    maskNet.mask = mask_reshaped\n",
    "    test(maskNet)\n",
    "    \n",
    "    for e in epsilons:\n",
    "        adv_crafter = FastGradientMethod(maskClassifier, eps=e)\n",
    "        x_test_adv = adv_crafter.generate(x=x_test[:N])\n",
    "        predictions = maskClassifier.predict(x_test_adv)\n",
    "        accuracy = 100.*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:N], axis=1)) / N)\n",
    "        accuracies.append(accuracy)\n",
    "        print(\"Epsilon: {}   Test Accuracy = {}\".format(e, accuracy))\n",
    "\n",
    "    results['accuracies'] = accuracies\n",
    "    results['epsilons'] = epsilons\n",
    "    fgsm_prune[pg] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C&W attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial test examples\n",
    "def CarliniL2(classifier, x_test, init_const=0.01):\n",
    "    attack = CarliniL2Method(classifier=classifier,\n",
    "                            confidence=0.0,\n",
    "                            targeted=False,\n",
    "                            learning_rate=0.01,\n",
    "                            binary_search_steps=1,\n",
    "                            initial_const=init_const,\n",
    "                            batch_size=1)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv\n",
    "\n",
    "def CarliniLInf(classifier, x_test, epsilon=0.005):\n",
    "    attack = CarliniLInfMethod(classifier=classifier, \n",
    "                              confidence=0.0,\n",
    "                              targeted=False, \n",
    "                              learning_rate=0.01,\n",
    "                              eps=epsilon, \n",
    "                              batch_size=128)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    return x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "x_test_adv = CarliniL2(classifier, x_test[:N])\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:N], axis=1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adversarial samples on pruned models and attack pruned models \n",
    "n = 100\n",
    "for (pg, mask) in masks.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "#     if masking a Conv layer it will need reshaping\n",
    "    mask_reshaped = torch.reshape(mask,(128, 16, 16)) \n",
    "    maskNet.mask = mask_reshaped\n",
    "    \n",
    "    x_test_adv_c2 = CarliniL2(maskClassifier, x_test[:n])\n",
    "    predictions = maskClassifier.predict(x_test_adv_c2)\n",
    "    acc = 100*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n)\n",
    "    \n",
    "    print(' Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "x_test_adv = CarliniLInf(classifier, x_test[:N])\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:N], axis=1)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adversarial samples on pruned models and attack pruned models \n",
    "n = 1000\n",
    "for (pg, mask) in masks.items():\n",
    "    print('\\n Pruned {}'.format(pg))\n",
    "    accuracies = []\n",
    "    results = dict()\n",
    "    \n",
    "#     if masking a Conv layer it will need reshaping\n",
    "    mask_reshaped = torch.reshape(mask,(256, 8, 8)) \n",
    "    maskNet.mask = mask_reshaped\n",
    "    \n",
    "    x_test_adv_c2 = CarliniLInf(maskClassifier, x_test[:n])\n",
    "    predictions = maskClassifier.predict(x_test_adv_c2)\n",
    "    acc = 100*(np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:n], axis=1)) / n)\n",
    "    \n",
    "    print(' Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
