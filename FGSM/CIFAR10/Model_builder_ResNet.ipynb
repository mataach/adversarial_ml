{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from art.utils import load_dataset\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "# x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "# x_test, y_test = x_test[:500], y_test[:500]\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1, 3).astype(np.float32)\n",
    "x_test = np.swapaxes(x_test, 1, 3).astype(np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n=7, res_option='A', use_dropout=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.res_option = res_option\n",
    "        self.use_dropout = use_dropout\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.layers1 = self._make_layer(n, 16, 16, 1)\n",
    "        self.layers2 = self._make_layer(n, 32, 16, 2)\n",
    "        self.layers3 = self._make_layer(n, 64, 32, 2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "    \n",
    "    def _make_layer(self, layer_count, channels, channels_in, stride):\n",
    "        return nn.Sequential(\n",
    "            ResBlock(channels, channels_in, stride, res_option=self.res_option, use_dropout=self.use_dropout),\n",
    "            *[ResBlock(channels) for _ in range(layer_count-1)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.layers1(out)\n",
    "        out = self.layers2(out)\n",
    "        out = self.layers3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_filters, channels_in=None, stride=1, res_option='A', use_dropout=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        # uses 1x1 convolutions for downsampling\n",
    "        if not channels_in or channels_in == num_filters:\n",
    "            channels_in = num_filters\n",
    "            self.projection = None\n",
    "        else:\n",
    "            if res_option == 'A':\n",
    "                self.projection = IdentityPadding(num_filters, channels_in, stride)\n",
    "            elif res_option == 'B':\n",
    "                self.projection = ConvProjection(num_filters, channels_in, stride)\n",
    "            elif res_option == 'C':\n",
    "                self.projection = AvgPoolPadding(num_filters, channels_in, stride)\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channels_in, num_filters, kernel_size=3, stride=stride, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1)\n",
    "        if self.use_dropout:\n",
    "            self.dropout = nn.Dropout(inplace=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.use_dropout:\n",
    "            out = self.dropout(out)\n",
    "        if self.projection:\n",
    "            residual = self.projection(x)\n",
    "        out += residual\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# various projection options to change number of filters in residual connection\n",
    "# option A from paper\n",
    "class IdentityPadding(nn.Module):\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(IdentityPadding, self).__init__()\n",
    "        # with kernel_size=1, max pooling is equivalent to identity mapping with stride\n",
    "        self.identity = nn.MaxPool2d(1, stride=stride)\n",
    "        self.num_zeros = num_filters - channels_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n",
    "        out = self.identity(out)\n",
    "        return out\n",
    "    \n",
    "# option B from paper\n",
    "class ConvProjection(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(ResA, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels_in, num_filters, kernel_size=1, stride=stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "# experimental option C\n",
    "class AvgPoolPadding(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, channels_in, stride):\n",
    "        super(AvgPoolPadding, self).__init__()\n",
    "        self.identity = nn.AvgPool2d(stride, stride=stride)\n",
    "        self.num_zeros = num_filters - channels_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n",
    "        out = self.identity(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(cl, opt, x, y):\n",
    "    x.to(device)\n",
    "    y.to(device)\n",
    "    #Reset gradients\n",
    "    opt.zero_grad()\n",
    "    #Train on real data\n",
    "    pred = cl(x)\n",
    "    pred.to(device)\n",
    "    err = F.nll_loss(F.log_softmax(pred, dim=0), y)\n",
    "    err.backward()\n",
    "    #Update optimizer\n",
    "    opt.step()\n",
    "    return err, pred\n",
    "\n",
    "def test_model(cl,test_loader): \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        cl.eval()\n",
    "        for data, target in test_loader:\n",
    "            output = cl(data.to(device))\n",
    "            pred = output.data.max(1, keepdim=True)[1].to(\"cpu\")\n",
    "            target = np.argmax(target, axis=1)\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        acc_test = float(correct.numpy() / len(test_loader.dataset))\n",
    "        \n",
    "    return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Test accuracy:  72.78 %\n",
      "Epoch  1 : Test accuracy:  75.11 %\n",
      "Epoch  2 : Test accuracy:  75.61 %\n",
      "Epoch  3 : Test accuracy:  71.88 %\n",
      "Epoch  4 : Test accuracy:  74.25 %\n",
      "Epoch  5 : Test accuracy:  75.59 %\n",
      "Epoch  6 : Test accuracy:  76.33 %\n",
      "Epoch  7 : Test accuracy:  75.13 %\n",
      "Epoch  8 : Test accuracy:  75.37 %\n",
      "Epoch  9 : Test accuracy:  76.28 %\n",
      "Performance in the trained model: \n",
      "Test accuracy:  76.28 %\n",
      "FINISHED!!!\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 10\n",
    "# e_losses = [] \n",
    "\n",
    "# # Load pre-trained model\n",
    "# cl = ResNet().to(device)\n",
    "\n",
    "# # optimizer\n",
    "# decay = 0\n",
    "# cl_opt = optim.Adam(cl.parameters(), lr=0.001, weight_decay=decay)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    cl.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        target = np.argmax(target, axis=1)  # transform from one-hot to int\n",
    "        c_error,c_pred = train_classifier(cl,cl_opt, data.to(device), target.to(device))\n",
    "        e_losses.append(c_error.cpu().data.numpy())\n",
    "    acc = test_model(cl,test_dataloader)\n",
    "    print(\"Epoch \", e, \": Test accuracy: \", 100*acc, \"%\")\n",
    "\n",
    "print(\"Performance in the trained model: \")\n",
    "acc_test = test_model(cl,test_dataloader)\n",
    "print(\"Test accuracy: \", 100*acc_test, \"%\")\n",
    "print(\"FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP-TF-GPU-2.1",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
